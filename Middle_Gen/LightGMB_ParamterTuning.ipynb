{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNu3m0ikEZGibfQ8y1Jnnrb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYiX3ps1eA7n","executionInfo":{"status":"ok","timestamp":1689390001502,"user_tz":240,"elapsed":688,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"9ebd857a-7481-491e-c9f8-1108e18fe3f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["11888    one thing I m amazed at be how close defender ...\n","22430                                              aiiight\n","49665    number 1 and only number 1 if you consider any...\n","6277       a powerful and insightful portrait of a uniq...\n","26297                follow my favorite youtuber jorraptor\n","Name: tweet, dtype: object\n","11888    2\n","22430    2\n","49665    3\n","6277     2\n","26297    0\n","Name: sentiment, dtype: int64\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report, accuracy_score\n","from lightgbm import LGBMClassifier\n","\n","# Read the CSV file into a DataFrame\n","tweet_data_int = pd.read_csv('train_nick.csv')\n","\n","# Convert 'tweet' column to string data type and remove non-string entries\n","tweet_data_int['tweet'] = tweet_data_int['tweet'].astype(str)\n","tweet_data_int = tweet_data_int[tweet_data_int['tweet'].apply(lambda x: isinstance(x, str))]\n","\n","# Join the list of words into a single string\n","tweet_data_int['tweet'] = tweet_data_int['tweet'].apply(lambda x: ''.join(x))\n","\n","# Split the data into features (X) and target (y)\n","X = tweet_data_int['tweet']\n","y = tweet_data_int['sentiment']\n","\n","# Split the data into training, validation, and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n","\n","print(X_train.head())\n","print(y_train.head())"]},{"cell_type":"code","source":["# Create a pipeline with TF-IDF vectorizer and LightGBM classifier\n","pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer()),\n","    ('lgbm', LGBMClassifier())\n","])\n","\n","# Define the parameter grid for grid search\n","param_grid = {\n","    'tfidf__max_features': [1000, 2000],\n","    'lgbm__num_leaves': [20, 30],\n","    'lgbm__learning_rate': [0.05, 0.1],\n","    'lgbm__n_estimators': [100, 200]\n","}\n","\n","# Perform grid search to find the best parameters\n","grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train, y_train)"],"metadata":{"id":"ggNeH5hxfPH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the best model and its parameters\n","best_model = grid_search.best_estimator_\n","best_params = grid_search.best_params_\n","\n","# Fit the best model on the training data\n","best_model.fit(X_train, y_train)\n","\n","# Get predictions on the test set\n","y_pred = best_model.predict(X_test)\n","\n","# Calculate accuracy for the best model\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# Compare accuracy before and after tuning\n","y_pred_initial = best_model.predict(X_test)\n","accuracy_initial = accuracy_score(y_test, y_pred_initial)\n","\n","# Print accuracy and best parameters\n","print(\"Accuracy (Best Model):\", accuracy)\n","print(\"Best Parameters:\", best_params)\n","print(\"Accuracy (Initial Model):\", accuracy_initial)\n","\n","# Print classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Quantitative Results\n","results = pd.DataFrame({'Metric': ['Accuracy', 'Mean Accuracy'],\n","                        'Value': [accuracy, np.mean(y_test == y_pred)]})\n","print(\"Quantitative Results:\")\n","print(results)\n","\n","# Learning Curves\n","train_scores = []\n","val_scores = []\n","param_range = np.arange(1, len(X_train)+1, 100)\n","for size in param_range:\n","    X_train_subset = X_train[:size]\n","    y_train_subset = y_train[:size]\n","\n","    best_model.fit(X_train_subset, y_train_subset)\n","\n","    train_pred = best_model.predict(X_train_subset)\n","    train_acc = accuracy_score(y_train_subset, train_pred)\n","    train_scores.append(train_acc)\n","\n","    val_pred = best_model.predict(X_val)\n","    val_acc = accuracy_score(y_val, val_pred)\n","    val_scores.append(val_acc)\n","\n","# Plotting learning curves\n","plt.figure(figsize=(10, 6))\n","plt.plot(param_range, train_scores, label='Training Accuracy')\n","plt.plot(param_range, val_scores, label='Validation Accuracy')\n","plt.xlabel('Training Set Size')\n","plt.ylabel('Accuracy')\n","plt.title('Learning Curves')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"mJdhlI9IfMCi"},"execution_count":null,"outputs":[]}]}
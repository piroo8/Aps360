{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPS92kngmrChnijWHfdV4fO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6mtHKphsGVRJ","executionInfo":{"status":"ok","timestamp":1691106841494,"user_tz":240,"elapsed":844,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"8391d6f8-f7a1-401b-e830-68ae68fd80bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYJzPFoQGQoj","executionInfo":{"status":"ok","timestamp":1691106853663,"user_tz":240,"elapsed":12170,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"959817d0-ad50-4055-e899-03e26b1b2ae3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.7.0.tar.gz (361 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/361.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m358.4/361.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.8/361.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-2.7.0-py2.py3-none-any.whl size=356563 sha256=b6e1ff112ecff2a383c159dec35676887448bb54e35e31ed77f0cc416a14d2ed\n","  Stored in directory: /root/.cache/pip/wheels/41/11/48/5df0b9727d5669c9174a141134f10304d1d78a3b89a4676f3d\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-2.7.0\n"]}],"source":["pip install emoji --upgrade"]},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BPtrjX9yGW50","executionInfo":{"status":"ok","timestamp":1691106858654,"user_tz":240,"elapsed":4994,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"96c4d35d-286a-45c9-c416-206bd1589bf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"]}]},{"cell_type":"code","source":["!pip install contractions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbZESrVGGYg7","executionInfo":{"status":"ok","timestamp":1691106866439,"user_tz":240,"elapsed":7789,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"abec65be-c041-4120-ef43-4964f8217f5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import emoji\n","\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.sentiment.util import mark_negation\n","import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","import contractions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXuI5rbGGZor","executionInfo":{"status":"ok","timestamp":1691106869388,"user_tz":240,"elapsed":2962,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"63c89be9-0477-446d-a4f8-5e9a01f20855"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZiKxYPmGa-j","executionInfo":{"status":"ok","timestamp":1691106869389,"user_tz":240,"elapsed":5,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"7f703979-9f5c-4189-ec2b-2b3fbdf25bcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Loading the data\n","train_path = \"/content/drive/MyDrive/Colab Notebooks/project/twitter_sentiment/twitter_training.csv\"\n","val_path = \"/content/drive/MyDrive/Colab Notebooks/project/twitter_sentiment/twitter_validation.csv\"\n","# Note: ideally data doesnt have column headers but we add them to easy manipulation\n","headers = [\"id\", \"company\", \"sentiment\", \"tweet\"]\n","df_train = pd.read_csv(train_path, names=headers)\n","df_val = pd.read_csv(val_path, names=headers)\n","\n","print(df_train.head())\n","print(df_val.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jBK6ciHGm1e","executionInfo":{"status":"ok","timestamp":1691106870843,"user_tz":240,"elapsed":1457,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"6305e127-164b-41a5-bdc1-66da543f9542"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     id      company sentiment  \\\n","0  2401  Borderlands  Positive   \n","1  2401  Borderlands  Positive   \n","2  2401  Borderlands  Positive   \n","3  2401  Borderlands  Positive   \n","4  2401  Borderlands  Positive   \n","\n","                                               tweet  \n","0  im getting on borderlands and i will murder yo...  \n","1  I am coming to the borders and I will kill you...  \n","2  im getting on borderlands and i will kill you ...  \n","3  im coming on borderlands and i will murder you...  \n","4  im getting on borderlands 2 and i will murder ...  \n","     id    company   sentiment  \\\n","0  3364   Facebook  Irrelevant   \n","1   352     Amazon     Neutral   \n","2  8312  Microsoft    Negative   \n","3  4371      CS-GO    Negative   \n","4  4433     Google     Neutral   \n","\n","                                               tweet  \n","0  I mentioned on Facebook that I was struggling ...  \n","1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n","2  @Microsoft Why do I pay for WORD when it funct...  \n","3  CSGO matchmaking is so full of closet hacking,...  \n","4  Now the President is slapping Americans in the...  \n"]}]},{"cell_type":"code","source":["abbreviations = {\n","    \"$\" : \" dollar \",\n","    \"€\" : \" euro \",\n","    \"4ao\" : \"for adults only\",\n","    \"a.m\" : \"before midday\",\n","    \"a3\" : \"anytime anywhere anyplace\",\n","    \"aamof\" : \"as a matter of fact\",\n","    \"acct\" : \"account\",\n","    \"adih\" : \"another day in hell\",\n","    \"afaic\" : \"as far as i am concerned\",\n","    \"afaict\" : \"as far as i can tell\",\n","    \"afaik\" : \"as far as i know\",\n","    \"afair\" : \"as far as i remember\",\n","    \"afk\" : \"away from keyboard\",\n","    \"app\" : \"application\",\n","    \"approx\" : \"approximately\",\n","    \"apps\" : \"applications\",\n","    \"asap\" : \"as soon as possible\",\n","    \"asl\" : \"age, sex, location\",\n","    \"atk\" : \"at the keyboard\",\n","    \"ave.\" : \"avenue\",\n","    \"aymm\" : \"are you my mother\",\n","    \"ayor\" : \"at your own risk\",\n","    \"b&b\" : \"bed and breakfast\",\n","    \"b+b\" : \"bed and breakfast\",\n","    \"b.c\" : \"before christ\",\n","    \"b2b\" : \"business to business\",\n","    \"b2c\" : \"business to customer\",\n","    \"b4\" : \"before\",\n","    \"b4n\" : \"bye for now\",\n","    \"b@u\" : \"back at you\",\n","    \"bae\" : \"before anyone else\",\n","    \"bak\" : \"back at keyboard\",\n","    \"bbbg\" : \"bye bye be good\",\n","    \"bbc\" : \"british broadcasting corporation\",\n","    \"bbias\" : \"be back in a second\",\n","    \"bbl\" : \"be back later\",\n","    \"bbs\" : \"be back soon\",\n","    \"be4\" : \"before\",\n","    \"bfn\" : \"bye for now\",\n","    \"blvd\" : \"boulevard\",\n","    \"bout\" : \"about\",\n","    \"brb\" : \"be right back\",\n","    \"bros\" : \"brothers\",\n","    \"brt\" : \"be right there\",\n","    \"bsaaw\" : \"big smile and a wink\",\n","    \"btw\" : \"by the way\",\n","    \"bwl\" : \"bursting with laughter\",\n","    \"c/o\" : \"care of\",\n","    \"cet\" : \"central european time\",\n","    \"cf\" : \"compare\",\n","    \"cia\" : \"central intelligence agency\",\n","    \"csl\" : \"can not stop laughing\",\n","    \"cu\" : \"see you\",\n","    \"cul8r\" : \"see you later\",\n","    \"cv\" : \"curriculum vitae\",\n","    \"cwot\" : \"complete waste of time\",\n","    \"cya\" : \"see you\",\n","    \"cyt\" : \"see you tomorrow\",\n","    \"dae\" : \"does anyone else\",\n","    \"dbmib\" : \"do not bother me i am busy\",\n","    \"diy\" : \"do it yourself\",\n","    \"dm\" : \"direct message\",\n","    \"dwh\" : \"during work hours\",\n","    \"e123\" : \"easy as one two three\",\n","    \"eet\" : \"eastern european time\",\n","    \"eg\" : \"example\",\n","    \"embm\" : \"early morning business meeting\",\n","    \"encl\" : \"enclosed\",\n","    \"encl.\" : \"enclosed\",\n","    \"etc\" : \"and so on\",\n","    \"faq\" : \"frequently asked questions\",\n","    \"fawc\" : \"for anyone who cares\",\n","    \"fb\" : \"facebook\",\n","    \"fc\" : \"fingers crossed\",\n","    \"fig\" : \"figure\",\n","    \"fimh\" : \"forever in my heart\",\n","    \"ft.\" : \"feet\",\n","    \"ft\" : \"featuring\",\n","    \"ftl\" : \"for the loss\",\n","    \"ftw\" : \"for the win\",\n","    \"fwiw\" : \"for what it is worth\",\n","    \"fyi\" : \"for your information\",\n","    \"g9\" : \"genius\",\n","    \"gahoy\" : \"get a hold of yourself\",\n","    \"gal\" : \"get a life\",\n","    \"gcse\" : \"general certificate of secondary education\",\n","    \"gfn\" : \"gone for now\",\n","    \"gg\" : \"good game\",\n","    \"gl\" : \"good luck\",\n","    \"glhf\" : \"good luck have fun\",\n","    \"gmt\" : \"greenwich mean time\",\n","    \"gmta\" : \"great minds think alike\",\n","    \"gn\" : \"good night\",\n","    \"g.o.a.t\" : \"greatest of all time\",\n","    \"goat\" : \"greatest of all time\",\n","    \"goi\" : \"get over it\",\n","    \"gps\" : \"global positioning system\",\n","    \"gr8\" : \"great\",\n","    \"gratz\" : \"congratulations\",\n","    \"gyal\" : \"girl\",\n","    \"h&c\" : \"hot and cold\",\n","    \"hp\" : \"horsepower\",\n","    \"hr\" : \"hour\",\n","    \"hrh\" : \"his royal highness\",\n","    \"ht\" : \"height\",\n","    \"ibrb\" : \"i will be right back\",\n","    \"ic\" : \"i see\",\n","    \"icq\" : \"i seek you\",\n","    \"icymi\" : \"in case you missed it\",\n","    \"idc\" : \"i do not care\",\n","    \"idgadf\" : \"i do not give a damn fuck\",\n","    \"idgaf\" : \"i do not give a fuck\",\n","    \"idk\" : \"i do not know\",\n","    \"ie\" : \"that is\",\n","    \"i.e\" : \"that is\",\n","    \"ifyp\" : \"i feel your pain\",\n","    \"IG\" : \"instagram\",\n","    \"iirc\" : \"if i remember correctly\",\n","    \"ilu\" : \"i love you\",\n","    \"ily\" : \"i love you\",\n","    \"imho\" : \"in my humble opinion\",\n","    \"imo\" : \"in my opinion\",\n","    \"imu\" : \"i miss you\",\n","    \"iow\" : \"in other words\",\n","    \"irl\" : \"in real life\",\n","    \"j4f\" : \"just for fun\",\n","    \"jic\" : \"just in case\",\n","    \"jk\" : \"just kidding\",\n","    \"jsyk\" : \"just so you know\",\n","    \"l8r\" : \"later\",\n","    \"lb\" : \"pound\",\n","    \"lbs\" : \"pounds\",\n","    \"ldr\" : \"long distance relationship\",\n","    \"lmao\" : \"laugh my ass off\",\n","    \"lmfao\" : \"laugh my fucking ass off\",\n","    \"lol\" : \"laughing out loud\",\n","    \"ltd\" : \"limited\",\n","    \"ltns\" : \"long time no see\",\n","    \"m8\" : \"mate\",\n","    \"mf\" : \"motherfucker\",\n","    \"mfs\" : \"motherfuckers\",\n","    \"mfw\" : \"my face when\",\n","    \"mofo\" : \"motherfucker\",\n","    \"mph\" : \"miles per hour\",\n","    \"mr\" : \"mister\",\n","    \"mrw\" : \"my reaction when\",\n","    \"ms\" : \"miss\",\n","    \"mte\" : \"my thoughts exactly\",\n","    \"nagi\" : \"not a good idea\",\n","    \"nbc\" : \"national broadcasting company\",\n","    \"nbd\" : \"not big deal\",\n","    \"nfs\" : \"not for sale\",\n","    \"ngl\" : \"not going to lie\",\n","    \"nhs\" : \"national health service\",\n","    \"nrn\" : \"no reply necessary\",\n","    \"nsfl\" : \"not safe for life\",\n","    \"nsfw\" : \"not safe for work\",\n","    \"nth\" : \"nice to have\",\n","    \"nvr\" : \"never\",\n","    \"nyc\" : \"new york city\",\n","    \"oc\" : \"original content\",\n","    \"og\" : \"original\",\n","    \"ohp\" : \"overhead projector\",\n","    \"oic\" : \"oh i see\",\n","    \"omdb\" : \"over my dead body\",\n","    \"omg\" : \"oh my god\",\n","    \"omw\" : \"on my way\",\n","    \"p.a\" : \"per annum\",\n","    \"p.m\" : \"after midday\",\n","    \"pm\" : \"prime minister\",\n","    \"poc\" : \"people of color\",\n","    \"pov\" : \"point of view\",\n","    \"pp\" : \"pages\",\n","    \"ppl\" : \"people\",\n","    \"prw\" : \"parents are watching\",\n","    \"ps\" : \"postscript\",\n","    \"pt\" : \"point\",\n","    \"ptb\" : \"please text back\",\n","    \"pto\" : \"please turn over\",\n","    \"qpsa\" : \"what happens\", #\"que pasa\",\n","    \"ratchet\" : \"rude\",\n","    \"rbtl\" : \"read between the lines\",\n","    \"rlrt\" : \"real life retweet\",\n","    \"rofl\" : \"rolling on the floor laughing\",\n","    \"roflol\" : \"rolling on the floor laughing out loud\",\n","    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n","    \"rt\" : \"retweet\",\n","    \"ruok\" : \"are you ok\",\n","    \"sfw\" : \"safe for work\",\n","    \"sk8\" : \"skate\",\n","    \"smh\" : \"shake my head\",\n","    \"sq\" : \"square\",\n","    \"srsly\" : \"seriously\",\n","    \"ssdd\" : \"same stuff different day\",\n","    \"tbh\" : \"to be honest\",\n","    \"tbs\" : \"tablespooful\",\n","    \"tbsp\" : \"tablespooful\",\n","    \"tfw\" : \"that feeling when\",\n","    \"thks\" : \"thank you\",\n","    \"tho\" : \"though\",\n","    \"thx\" : \"thank you\",\n","    \"tia\" : \"thanks in advance\",\n","    \"til\" : \"today i learned\",\n","    \"tl;dr\" : \"too long i did not read\",\n","    \"tldr\" : \"too long i did not read\",\n","    \"tmb\" : \"tweet me back\",\n","    \"tntl\" : \"trying not to laugh\",\n","    \"ttyl\" : \"talk to you later\",\n","    \"u\" : \"you\",\n","    \"u2\" : \"you too\",\n","    \"u4e\" : \"yours for ever\",\n","    \"utc\" : \"coordinated universal time\",\n","    \"w/\" : \"with\",\n","    \"w/o\" : \"without\",\n","    \"w8\" : \"wait\",\n","    \"wassup\" : \"what is up\",\n","    \"wb\" : \"welcome back\",\n","    \"wtf\" : \"what the fuck\",\n","    \"wtg\" : \"way to go\",\n","    \"wtpa\" : \"where the party at\",\n","    \"wuf\" : \"where are you from\",\n","    \"wuzup\" : \"what is up\",\n","    \"wywh\" : \"wish you were here\",\n","    \"yd\" : \"yard\",\n","    \"ygtr\" : \"you got that right\",\n","    \"ynk\" : \"you never know\",\n","    \"zzz\" : \"sleeping bored and tired\"\n","}"],"metadata":{"id":"HX2bpl4AGzhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Remove NaN values\n","def remove_nan_values(df, columns):\n","    for column in columns:\n","        df = df[df[column].notna()]  # Remove rows with NaN values\n","        df = df[df[column].astype(bool)]  # Remove rows with empty lists or lists with only white spaces\n","    return df\n","\n","# Step 2: Assign tweet labels\n","def one_hot_encode_sentiments(sentiment): #make neutral and irrelavent same number, and look over\n","    if sentiment == 'Positive':\n","        return 2\n","    elif sentiment == 'Negative':\n","        return 0\n","    elif sentiment == 'Neutral':\n","        return 1\n","    elif sentiment == 'Irrelevant':\n","        return 1\n","\n","def expand_slang(text):\n","    tokens = word_tokenize(text)\n","    tokens = [abbreviations.get(word.lower(), word) for word in tokens]\n","    text = ' '.join(tokens)\n","    return text\n","\n","\n","# Step 3: Clean tweets\n","def clean_tweets(tweet):\n","    # Remove @mentions\n","    tweet = re.sub(r'@\\w+', '', tweet)\n","\n","    # Remove URLs\n","    tweet = re.sub(r'http\\S+|www\\S+', '', tweet)\n","\n","    # Remove hashtags\n","    tweet = re.sub(r'#\\w+', '', tweet)\n","\n","    # Convert emojis to text\n","    tweet = emoji.demojize(tweet)\n","\n","    # Expand contractions\n","    tweet = contractions.fix(tweet)\n","    ##############################3\n","\n","    # Remove numbers\n","    tweet = re.sub(r'\\d+', '', tweet)\n","\n","    # Remove punctuation\n","    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n","\n","    # Remove excessive whitespace\n","    tweet = re.sub(r'\\s+', ' ', tweet)\n","\n","    # Standardize repeated characters\n","    tweet = re.sub(r'(.)\\1+', r'\\1\\1', tweet)\n","\n","    #Expand slang terms\n","    tweet = expand_slang(tweet)\n","\n","    # Tokenize the tweet\n","    tokens = word_tokenize(tweet)\n","\n","    # Lowercase and normalize\n","    tokens = [token.lower() for token in tokens]\n","\n","    # Remove stop words\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [token for token in tokens if token.lower() not in stop_words]\n","\n","    # Handle abbreviations and acronyms\n","    abbreviation_words = {\"lol\": \"laughing out loud\", \"btw\": \"by the way\"}  # Add more as needed\n","    tokens = [abbreviation_words.get(token.lower(), token) for token in tokens]\n","\n","    # Lemmatization\n","    lemmatizer = WordNetLemmatizer()\n","    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","\n","    # Handle negation using mark_negation\n","    #tokens = mark_negation(tokens)\n","    #tweet = \"I don't like this product. It is not good.\"\n","    #['I', \"don't\", 'like_NEG', 'this_NEG', 'product_NEG', '.', 'It_NEG', 'is_NEG', 'not_NEG', 'good_NEG', '.']\n","\n","    # Uncomment the following lines to include POS tags as comments\n","    #pos_tags = nltk.pos_tag(tokens)\n","    #tokens_with_pos = [f\"{token}/{pos}\" for token, pos in pos_tags]\n","\n","    return tokens"],"metadata":{"id":"H9qMwKl5G1Is"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Remove NaN values\n","columns_to_check = [\"id\", \"company\", \"sentiment\", \"tweet\"]\n","df_train = remove_nan_values(df_train, columns_to_check)\n","df_val = remove_nan_values(df_val, columns_to_check)\n","\n","print(df_train.head())\n","print(df_val.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4XLR8RRG7PD","executionInfo":{"status":"ok","timestamp":1691106870990,"user_tz":240,"elapsed":155,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"b8c5d446-4755-4b56-c25d-bc84b6a3e493"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     id      company sentiment  \\\n","0  2401  Borderlands  Positive   \n","1  2401  Borderlands  Positive   \n","2  2401  Borderlands  Positive   \n","3  2401  Borderlands  Positive   \n","4  2401  Borderlands  Positive   \n","\n","                                               tweet  \n","0  im getting on borderlands and i will murder yo...  \n","1  I am coming to the borders and I will kill you...  \n","2  im getting on borderlands and i will kill you ...  \n","3  im coming on borderlands and i will murder you...  \n","4  im getting on borderlands 2 and i will murder ...  \n","     id    company   sentiment  \\\n","0  3364   Facebook  Irrelevant   \n","1   352     Amazon     Neutral   \n","2  8312  Microsoft    Negative   \n","3  4371      CS-GO    Negative   \n","4  4433     Google     Neutral   \n","\n","                                               tweet  \n","0  I mentioned on Facebook that I was struggling ...  \n","1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n","2  @Microsoft Why do I pay for WORD when it funct...  \n","3  CSGO matchmaking is so full of closet hacking,...  \n","4  Now the President is slapping Americans in the...  \n"]}]},{"cell_type":"code","source":["# Step 2: Assign tweet labels and remove rows with 'Irrelevant' sentiment\n","df_train['sentiment'] = df_train['sentiment'].apply(one_hot_encode_sentiments)\n","df_val['sentiment'] = df_val['sentiment'].apply(one_hot_encode_sentiments)\n","\n","# Remove rows with 'Irrelevant' sentiment from the DataFrame\n","df_train = df_train.dropna(subset=['sentiment'])\n","df_val = df_val.dropna(subset=['sentiment'])\n","\n","print(df_train.head())\n","print(df_val.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obq9v6IMG8i9","executionInfo":{"status":"ok","timestamp":1691106870990,"user_tz":240,"elapsed":3,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"b506731f-d0c4-40b3-f2a0-72d1af50b701"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     id      company  sentiment  \\\n","0  2401  Borderlands          2   \n","1  2401  Borderlands          2   \n","2  2401  Borderlands          2   \n","3  2401  Borderlands          2   \n","4  2401  Borderlands          2   \n","\n","                                               tweet  \n","0  im getting on borderlands and i will murder yo...  \n","1  I am coming to the borders and I will kill you...  \n","2  im getting on borderlands and i will kill you ...  \n","3  im coming on borderlands and i will murder you...  \n","4  im getting on borderlands 2 and i will murder ...  \n","     id    company  sentiment  \\\n","0  3364   Facebook          1   \n","1   352     Amazon          1   \n","2  8312  Microsoft          0   \n","3  4371      CS-GO          0   \n","4  4433     Google          1   \n","\n","                                               tweet  \n","0  I mentioned on Facebook that I was struggling ...  \n","1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n","2  @Microsoft Why do I pay for WORD when it funct...  \n","3  CSGO matchmaking is so full of closet hacking,...  \n","4  Now the President is slapping Americans in the...  \n"]}]},{"cell_type":"code","source":["# Step 3: Clean tweets\n","df_train['tweet'] = df_train['tweet'].apply(clean_tweets)\n","df_val['tweet'] = df_val['tweet'].apply(clean_tweets)\n","\n","print(df_train.head())\n","print(df_val.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_5aw4nVG91C","executionInfo":{"status":"ok","timestamp":1691106919797,"user_tz":240,"elapsed":48809,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"2ca290d8-bb4f-4d02-c442-37161d80059a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     id      company  sentiment                          tweet\n","0  2401  Borderlands          2  [getting, borderland, murder]\n","1  2401  Borderlands          2         [coming, border, kill]\n","2  2401  Borderlands          2    [getting, borderland, kill]\n","3  2401  Borderlands          2   [coming, borderland, murder]\n","4  2401  Borderlands          2  [getting, borderland, murder]\n","     id    company  sentiment  \\\n","0  3364   Facebook          1   \n","1   352     Amazon          1   \n","2  8312  Microsoft          0   \n","3  4371      CS-GO          0   \n","4  4433     Google          1   \n","\n","                                               tweet  \n","0  [mentioned, facebook, struggling, motivation, ...  \n","1  [british, broadcasting, corporation, news, ama...  \n","2  [pay, word, function, poorly, chromebook, face...  \n","3  [csgo, matchmaking, full, closet, hacking, tru...  \n","4  [president, slapping, american, face, really, ...  \n"]}]},{"cell_type":"code","source":["# Step 1: Remove NaN values\n","columns_to_check = [\"id\", \"company\", \"sentiment\", \"tweet\"]\n","df_train = remove_nan_values(df_train, columns_to_check)\n","df_val = remove_nan_values(df_val, columns_to_check)\n","\n","print(df_train.head())\n","print(df_val.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bv96Y-HCG_XA","executionInfo":{"status":"ok","timestamp":1691106919798,"user_tz":240,"elapsed":12,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"35e509aa-b9ca-4564-df38-e50110045ef1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     id      company  sentiment                          tweet\n","0  2401  Borderlands          2  [getting, borderland, murder]\n","1  2401  Borderlands          2         [coming, border, kill]\n","2  2401  Borderlands          2    [getting, borderland, kill]\n","3  2401  Borderlands          2   [coming, borderland, murder]\n","4  2401  Borderlands          2  [getting, borderland, murder]\n","      id               company  sentiment  \\\n","0   3364              Facebook          1   \n","1    352                Amazon          1   \n","4   4433                Google          1   \n","6   7925             MaddenNFL          2   \n","7  11332  TomClancysRainbowSix          2   \n","\n","                                               tweet  \n","0  [mentioned, facebook, struggling, motivation, ...  \n","1  [british, broadcasting, corporation, news, ama...  \n","4  [president, slapping, american, face, really, ...  \n","6  [thank, new, te, austin, hooper, orange, brown...  \n","7  [rocket, league, sea, thief, rainbow, six, sie...  \n"]}]},{"cell_type":"code","source":["# Print the resulting DataFrame\n","print(df_train.head())\n","print(df_val.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zD3zM14xHAlZ","executionInfo":{"status":"ok","timestamp":1691106919798,"user_tz":240,"elapsed":11,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"4ed14f8a-1a09-4f58-c950-5818dab4fd0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     id      company  sentiment                          tweet\n","0  2401  Borderlands          2  [getting, borderland, murder]\n","1  2401  Borderlands          2         [coming, border, kill]\n","2  2401  Borderlands          2    [getting, borderland, kill]\n","3  2401  Borderlands          2   [coming, borderland, murder]\n","4  2401  Borderlands          2  [getting, borderland, murder]\n","      id               company  sentiment  \\\n","0   3364              Facebook          1   \n","1    352                Amazon          1   \n","4   4433                Google          1   \n","6   7925             MaddenNFL          2   \n","7  11332  TomClancysRainbowSix          2   \n","\n","                                               tweet  \n","0  [mentioned, facebook, struggling, motivation, ...  \n","1  [british, broadcasting, corporation, news, ama...  \n","4  [president, slapping, american, face, really, ...  \n","6  [thank, new, te, austin, hooper, orange, brown...  \n","7  [rocket, league, sea, thief, rainbow, six, sie...  \n"]}]},{"cell_type":"code","source":["# Assuming your DataFrame is named df\n","import torch\n","# Drop the 'id' column\n","df_train_new = df_train.drop('id', axis=1)\n","df_val_new = df_val.drop('id', axis=1)\n","\n","# Export the DataFrame to a CSV file\n","df_train_new.to_csv('df_train_new_int.csv', index=False)\n","df_val_new.to_csv('df_val_new_int.csv', index=False)"],"metadata":{"id":"OqMQesJiHCzv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df_train_new[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NojZ5_e5HEhs","executionInfo":{"status":"ok","timestamp":1691106924535,"user_tz":240,"elapsed":21,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"cf705846-355f-4b58-d1b3-6264afa074e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       company  sentiment                          tweet\n","0  Borderlands          2  [getting, borderland, murder]\n","1  Borderlands          2         [coming, border, kill]\n","2  Borderlands          2    [getting, borderland, kill]\n","3  Borderlands          2   [coming, borderland, murder]\n","4  Borderlands          2  [getting, borderland, murder]\n"]}]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","from collections import Counter\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Load GloVe embeddings\n","def load_glove_embeddings(embeddings_path):\n","    embeddings_index = {}\n","    with open(embeddings_path, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            coefs = torch.tensor([float(val) for val in values[1:]])\n","            embeddings_index[word] = coefs\n","    return embeddings_index\n","\n","def get_vocab_dict(word_counts):\n","    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n","    vocab_dict = {word: idx for idx, (word, _) in enumerate(sorted_words)}\n","    return vocab_dict\n","\n","def indices_to_embeddings(indices, embeddings_index, embedding_dim, vocab_dict):\n","    embeddings = []\n","    for idx in indices:\n","        word = list(vocab_dict.keys())[list(vocab_dict.values()).index(idx)]\n","        if word in embeddings_index:\n","            embeddings.append(embeddings_index[word])\n","        else:\n","            embeddings.append(torch.zeros(embedding_dim))\n","    return embeddings\n","\n","# Paths\n","glove_path = \"glove.twitter.27B.100d.txt\"  # Replace with your actual path\n","data_path_train = \"df_train_new_int.csv\"  # Replace with your actual path\n","data_path_valid = \"df_val_new_int.csv\"  # Replace with your actual path\n","\n","# Load data\n","df_train_new = pd.read_csv(data_path_train)\n","df_val_new = pd.read_csv(data_path_valid)\n","\n","# Flatten the list of lists into a single list\n","all_words = [word for sublist in df_train_new['tweet'] for word in sublist]\n","all_words_valid = [word for sublist in df_val_new['tweet'] for word in sublist]\n","\n","# Create a vocabulary dictionary with words ordered by frequency\n","word_counts = Counter(all_words + all_words_valid)\n","vocab_dict = get_vocab_dict(word_counts)\n","\n","# Convert words to indices for each tweet\n","sequences_of_indices_train = [[vocab_dict[word] for word in sublist] for sublist in df_train_new['tweet']]\n","sequences_of_indices_valid = [[vocab_dict[word] for word in sublist] for sublist in df_val_new['tweet']]\n","\n","# Load GloVe embeddings\n","glove_embeddings = load_glove_embeddings(glove_path)\n","\n","# Convert indices to GloVe embeddings\n","embedding_dim = 100  # Assuming you're using 100-dimensional GloVe embeddings\n","\n","train_embeddings = [indices_to_embeddings(seq, glove_embeddings, embedding_dim, vocab_dict) for seq in sequences_of_indices_train]\n","valid_embeddings = [indices_to_embeddings(seq, glove_embeddings, embedding_dim, vocab_dict) for seq in sequences_of_indices_valid]\n","\n","# Ensure train_embeddings and valid_embeddings are lists of lists of tensors\n","train_embeddings = [torch.stack(embedding_list) for embedding_list in train_embeddings]\n","valid_embeddings = [torch.stack(embedding_list) for embedding_list in valid_embeddings]\n","\n","max_train_seq_length = 100\n","\n","# Pad sequences and create tensors\n","padded_train_embeddings = pad_sequence(\n","    [torch.cat((seq, torch.zeros(max_train_seq_length - len(seq), embedding_dim))) if len(seq) < max_train_seq_length else seq[:max_train_seq_length] for seq in train_embeddings],\n","    batch_first=True, padding_value=0.0\n",")\n","\n","padded_valid_embeddings = pad_sequence(\n","    [torch.cat((seq, torch.zeros(max_train_seq_length - len(seq), embedding_dim))) if len(seq) < max_train_seq_length else seq[:max_train_seq_length] for seq in valid_embeddings],\n","    batch_first=True, padding_value=0.0\n",")\n","\n","# Convert labels to tensors\n","train_labels = torch.tensor(df_train_new['sentiment'].values, dtype=torch.long)\n","valid_labels = torch.tensor(df_val_new['sentiment'].values, dtype=torch.long)\n","\n","# Create datasets and data loaders\n","batch_size = 32\n","train_dataset = TensorDataset(padded_train_embeddings, train_labels)\n","valid_dataset = TensorDataset(padded_valid_embeddings, valid_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Print shapes for verification\n","print(\"Train dataset shape:\", padded_train_embeddings.shape)\n","print(\"Valid dataset shape:\", padded_valid_embeddings.shape)"],"metadata":{"id":"h5Gww7ThyEd8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import confusion_matrix\n","import numpy\n","\n","class SentimentRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, dropout_prob=0.0):\n","        super(SentimentRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        # Define the LSTM layer\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n","\n","        # Define the fully connected layer for sentiment prediction\n","        self.fc = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device).to(self.lstm.weight_ih_l0.dtype)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device).to(self.lstm.weight_ih_l0.dtype)\n","\n","        x = x.to(self.lstm.weight_ih_l0.dtype)\n","        out, _ = self.lstm(x, (h0, c0))\n","\n","        out = out[:, -1, :]\n","\n","        out = self.fc(out)\n","\n","        return out\n","\n","def train(model, train_dataloader, learning_rate, epochs, optimizer):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    optimizer = optimizer\n","    loss_fn = nn.BCEWithLogitsLoss()\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        correct_predictions = 0\n","        total_predictions = 0\n","\n","        for batch in train_dataloader:\n","            inputs = batch[0].to(device)\n","            labels = batch[1].to(device).float()\n","\n","            inputs = inputs.unsqueeze(1)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            outputs = outputs.view(-1, 1)\n","\n","            labels = labels.view(-1, 1)\n","            loss = loss_fn(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","            predicted_probs = torch.sigmoid(outputs)\n","            predicted_classes = (predicted_probs > 0.5).float()\n","\n","            correct_predictions += (predicted_classes == labels).sum().item()\n","            total_predictions += labels.size(0)\n","\n","        training_accuracy = correct_predictions / total_predictions\n","        epoch_loss = running_loss / len(train_dataloader)\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss}, Accuracy: {training_accuracy * 100}%\")\n","\n","    return training_accuracy\n","\n","def evaluate(model, dataloader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    model.eval()  # Set the model to evaluation mode\n","    all_labels = []\n","    all_predictions = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            inputs = batch[0].to(device)\n","            labels = batch[1].to(device).float()\n","\n","            inputs = inputs.unsqueeze(1)\n","            outputs = model(inputs)\n","            predicted_probs = torch.sigmoid(outputs)\n","            predicted_classes = (predicted_probs > 0.5).float()\n","\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predictions.extend(predicted_classes.cpu().numpy())\n","\n","    confusion = confusion_matrix(all_labels, all_predictions)\n","    return confusion"],"metadata":{"id":"8TYhhS-oJC_4","executionInfo":{"status":"ok","timestamp":1691109398310,"user_tz":240,"elapsed":6555,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["compare = SentimentRNN(embedding_dim, 128, 3, 0.8)\n","train(compare, train_loader, 5e-05, 5, torch.optim.Adam(compare.parameters(), lr=5e-05))\n","\n","confusion_matrix = evaluate(compare, valid_loader)\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCQKFBuFJVJn","executionInfo":{"status":"ok","timestamp":1691102193227,"user_tz":240,"elapsed":25959,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"5e3af094-2f05-492a-ab92-ed0e41501218"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Loss: -0.9152013858437301, Accuracy: 59.867010718539106%\n","Epoch [2/5], Loss: -6.912426474132235, Accuracy: 59.9801508535133%\n","Epoch [3/5], Loss: -11.080893274034773, Accuracy: 60.027788805081386%\n","Epoch [4/5], Loss: -14.460995781005375, Accuracy: 60.0396982929734%\n","Epoch [5/5], Loss: -17.61753231381613, Accuracy: 60.0396982929734%\n","Confusion Matrix:\n","[[457   0]\n"," [277   0]]\n"]}]},{"cell_type":"code","source":["pip install hyperopt"],"metadata":{"id":"4Qb_II8-JzIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from hyperopt import hp, fmin, tpe, Trials\n","\n","# Define the hyperparameter search space\n","space = {\n","    'lr': hp.choice('lr', [1e-5, 1e-4, 1e-3, 1e-2, 5e-5, 5e-4]),\n","    'hidden_size': hp.choice('hidden_size', [32, 64, 128, 256]),\n","    'num_layers': hp.choice('num_layers', [1, 2, 3]),\n","    'dropout': hp.choice('dropout', [0.0, 0.2,0.35, 0.5, 0.75,0.8,1]),  # Dropout rate\n","    'optimizer': hp.choice('optimizer', ['adam', 'sgd', 'rmsprop']),  # Optimizer choice\n","    'epochs': 2  # Run each model for 1 epoch\n","}\n","\n","# Initialize a list to store the top 10 hyperparameter configurations and their accuracies\n","top_configs = []\n","\n","# Define the objective function to optimize (in this case, the negative accuracy)\n","def objective(params):\n","    lr = params['lr']\n","    hidden_size = params['hidden_size']\n","    num_layers = params['num_layers']\n","    dropout = params['dropout']\n","    optimizer_choice = params['optimizer']\n","    epochs = params['epochs']\n","\n","    # Create the model with the given hyperparameters\n","    model = SentimentRNN(198, hidden_size, num_layers, dropout)\n","\n","    # Choose optimizer\n","    optimizer = None\n","    if optimizer_choice == 'adam':\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    elif optimizer_choice == 'sgd':\n","        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","    elif optimizer_choice == 'rmsprop':\n","        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n","\n","    # Train the model and get the accuracy\n","    accuracy = train(model, train_loader, lr, epochs, optimizer)\n","\n","    # Add the hyperparameters and accuracy to the top_configs list\n","    top_configs.append({'lr': lr, 'hidden_size': hidden_size, 'num_layers': num_layers,\n","                        'dropout': dropout, 'optimizer': optimizer_choice,\n","                        'accuracy': accuracy})\n","\n","    # Since hyperopt minimizes the objective function, we need to return the negative accuracy\n","    return -accuracy\n","\n","# Initialize the Trials object to track the optimization process\n","trials = Trials()\n","\n","# Run the hyperparameter search using the Tree of Parzen Estimators (TPE) algorithm\n","best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)\n","\n","# Sort the top_configs list based on accuracy in descending order\n","top_configs.sort(key=lambda x: x['accuracy'], reverse=True)\n","\n","# Print the 10 best hyperparameter configurations and their accuracies\n","for i, config in enumerate(top_configs[:10]):\n","    print(f\"Top {i+1} Hyperparameters:\")\n","    print(f\"Learning Rate: {config['lr']}\")\n","    print(f\"Hidden Layer Size: {config['hidden_size']}\")\n","    print(f\"Number of Hidden Layers: {config['num_layers']}\")\n","    print(f\"Dropout Rate: {config['dropout']}\")\n","    print(f\"Optimizer: {config['optimizer']}\")\n","    print(f\"Accuracy: {config['accuracy']}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"1tB7hZnhJ0JO","executionInfo":{"status":"error","timestamp":1691101293251,"user_tz":240,"elapsed":159667,"user":{"displayName":"Pierre Ishak","userId":"08507075842828312856"}},"outputId":"321e7f33-065a-4cf0-d68c-72d4895e02ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/2], Loss: -66.68634116216312, Accuracy: 59.960301707026595%\n","  0%|          | 0/100 [02:39<?, ?trial/s, best loss=?]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-a5206022efb7>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Run the hyperparameter search using the Tree of Parzen Estimators (TPE) algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Sort the top_configs list based on accuracy in descending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-69-a5206022efb7>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Train the model and get the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Add the hyperparameters and accuracy to the top_configs list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-66-9cee4a4b9bf7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, learning_rate, epochs, optimizer)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 state_steps)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    282\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","train_path = \"/content/drive/MyDrive/Colab Notebooks/project/twitter_sentiment/sentiment-emotion-labelled_Dell_tweets.csv\"\n","# use pathlib to load path\n","df = pd.read_csv(train_path, error_bad_lines=False)\n","\n","fig = plt.figure(figsize=(8,5))\n","ax = sns.barplot(x=df.sentiment.unique(),y=df.sentiment.value_counts());\n","ax.set(xlabel='Labels')\n","# Note: The label distribution is not even!"],"metadata":{"id":"WXSo7Ke6J4no"},"execution_count":null,"outputs":[]}]}